{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fetch data from the api\n",
    "def fetch_data_from_api(url, params=None):\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error fetching data: {response.text}\")\n",
    "        return {}\n",
    "\n",
    "# function to get quotes from the api\n",
    "def get_quotes(symbol, api_key):\n",
    "    quote_url = f\"https://finnhub.io/api/v1/quote?symbol={symbol}&token={api_key}\"\n",
    "    return fetch_data_from_api(quote_url)\n",
    "\n",
    "# function to get financials as reported from the api\n",
    "def get_financials_reported(symbol, api_key):\n",
    "    reported_financials_url = f\"https://finnhub.io/api/v1/stock/financials-reported?symbol={symbol}&token={api_key}\"\n",
    "    return fetch_data_from_api(reported_financials_url)\n",
    "\n",
    "# function to get company basic financials from the api\n",
    "def get_company_basic_financials(symbol, api_key):\n",
    "    basic_financials_url = f\"https://finnhub.io/api/v1/stock/metric?symbol={symbol}&metric=all&token={api_key}\"\n",
    "    return fetch_data_from_api(basic_financials_url)\n",
    "\n",
    "# function to get company profile from api\n",
    "def get_company_profile(symbol, api_key):\n",
    "    profile_url = f\"https://finnhub.io/api/v1/stock/profile2?symbol={symbol}&token={api_key}\"\n",
    "    return fetch_data_from_api(profile_url)\n",
    "\n",
    "# function to get company news from the api\n",
    "def get_company_news(symbol, api_key, start_date, end_date):\n",
    "    news_url = f\"https://finnhub.io/api/v1/company-news?symbol={symbol}&from={start_date}&to={end_date}&token={api_key}\"\n",
    "    return fetch_data_from_api(news_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract financial data from json response\n",
    "def extract_financial_data(data, section, concepts=None):\n",
    "    financial_data = []\n",
    "    if 'data' in data:\n",
    "        for report in data['data']:\n",
    "            # check if the section is present in the report\n",
    "            if 'report' in report and section in report['report']:\n",
    "                section_data = report['report'][section]\n",
    "                if concepts:\n",
    "                    section_data = [item for item in section_data if item['concept'] in concepts]\n",
    "                financial_data.extend(section_data)\n",
    "    return financial_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process and flatten basic_financials data\n",
    "def process_basic_financials_data(data, symbol):\n",
    "    # check if data has metric key\n",
    "    if 'metric' not in data:\n",
    "        print(f\"No 'metric' data available for {symbol}.\")\n",
    "        return pd.DataFrame()\n",
    "    # extract relevant metrics\n",
    "    metrics = data['metric']\n",
    "    relevant_keys = [\n",
    "        'quickRatioAnnual', 'currentRatioAnnual', 'netProfitMarginAnnual', 'inventoryTurnoverAnnual', 'grossMarginAnnual', 'totalDebt/totalEquityAnnual',\n",
    "        'assetTurnoverAnnual', 'receivablesTurnoverAnnual', 'roeTTM', 'epsAnnual', 'roiAnnual', 'cashFlowPerShareAnnual', 'ebitdPerShareAnnual', 'ebitdaCagr5Y', 'revenueGrowthTTMYoy'\n",
    "    ]\n",
    "    # create a dataframe with relevant metrics\n",
    "    relevant_metrics = {k: metrics.get(k) for k in relevant_keys}\n",
    "    relevant_metrics['symbol'] = symbol\n",
    "    return pd.DataFrame([relevant_metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process and flatten company news data\n",
    "def process_news_data(news_data, symbol):\n",
    "    processed_news = []\n",
    "    for news_item in news_data:\n",
    "        processed_news.append({\n",
    "            'symbol': symbol,\n",
    "            'datetime': pd.to_datetime(news_item['datetime'], unit='s'),  # Convert UNIX timestamp to datetime\n",
    "            'headline': news_item['headline'],\n",
    "            'source': news_item['source'],\n",
    "            'summary': news_item['summary'],\n",
    "            'url': news_item['url']\n",
    "        })\n",
    "    return processed_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# connection parameters\n",
    "username = os.getenv('username')\n",
    "password = os.getenv('password')\n",
    "host = os.getenv('host')\n",
    "port = os.getenv('port')\n",
    "database = os.getenv('database')\n",
    "\n",
    "api_key = os.getenv('FINNHUB_API_KEY')\n",
    "\n",
    "# engine for connecting to db\n",
    "engine = create_engine(f'mysql+pymysql://{username}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "# define the start and end dates for the data fetch\n",
    "end_date = datetime.now() - timedelta(days=1)\n",
    "start_date = end_date - timedelta(days=364)\n",
    "formatted_start_date = datetime.strptime(start_date.strftime('%Y-%m-%d'), '%Y-%m-%d')\n",
    "formatted_end_date = datetime.strptime(end_date.strftime('%Y-%m-%d'), '%Y-%m-%d')\n",
    "\n",
    "# list of companies and concepts to fetch\n",
    "company_symbols = [\"JPM\", \"GS\", \"C\", \"JLL\", \"DIS\", \"TPR\", \"F\", \"XOM\", \"AAPL\", \"AMZN\", \"PFE\", \"MRK\"]\n",
    "concepts = ['us-gaap_AssetsCurrent', 'us-gaap_AssetsNoncurrent', 'us-gaap_Assets',\n",
    "            'us-gaap_LiabilitiesCurrent', 'us-gaap_LiabilitiesNoncurrent', 'us-gaap_Liabilities',\n",
    "            'us-gaap_StockholdersEquity', 'us-gaap_CommonStocksIncludingAdditionalPaidInCapital',\n",
    "            'us-gaap_RetainedEarningsAccumulatedDeficit']\n",
    "\n",
    "# create lists to store data\n",
    "quotes_data = []\n",
    "financials_reported_data = []\n",
    "basic_financials_data = []\n",
    "symbols_data = []\n",
    "news_data = []\n",
    "\n",
    "# loop through each company symbol\n",
    "for symbol in company_symbols:\n",
    "    \n",
    "    # fetch and process company profile\n",
    "    profile_data = get_company_profile(symbol, api_key)\n",
    "    description = profile_data.get('name', 'N/A') \n",
    "    symbols_data.append({'symbol': symbol, 'description': description})\n",
    "\n",
    "    # fetch and process quotes\n",
    "    quote = get_quotes(symbol, api_key)\n",
    "    if quote:\n",
    "        quote['symbol'] = symbol\n",
    "        quotes_data.append(quote)\n",
    "\n",
    "    # fetch and process financials reported\n",
    "    financial_data = get_financials_reported(symbol, api_key)\n",
    "    bs_data = extract_financial_data(financial_data, 'bs', concepts)\n",
    "    for item in bs_data:\n",
    "        item['symbol'] = symbol\n",
    "    financials_reported_data.extend(bs_data)\n",
    "\n",
    "    # fetch and process basic financials\n",
    "    basic_financials_response = get_company_basic_financials(symbol, api_key)\n",
    "    if basic_financials_response:\n",
    "        processed_data = process_basic_financials_data(basic_financials_response, symbol)\n",
    "        basic_financials_data.append(processed_data)\n",
    "\n",
    "    # fetch and process news\n",
    "    news_response = get_company_news(symbol, api_key, formatted_start_date.strftime('%Y-%m-%d'), formatted_end_date.strftime('%Y-%m-%d'))\n",
    "    if news_response:\n",
    "        processed_news = process_news_data(news_response, symbol)\n",
    "        news_data.extend(processed_news)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "# convert lists to dfs\n",
    "symbols_df = pd.DataFrame(symbols_data)\n",
    "quotes_df = pd.DataFrame(quotes_data)\n",
    "financials_reported_df = pd.DataFrame(financials_reported_data)\n",
    "basic_financials_with_median_df = pd.concat(basic_financials_data, ignore_index=True)\n",
    "symbols_df = pd.DataFrame({'symbol': company_symbols})\n",
    "news_df = pd.DataFrame(news_data)\n",
    "\n",
    "# handle missing values by imputing with median, excluding 'symbol'\n",
    "numerical_cols = basic_financials_with_median_df.columns.drop('symbol') \n",
    "medians = basic_financials_with_median_df[numerical_cols].median()\n",
    "basic_financials_with_median_df[numerical_cols] = basic_financials_with_median_df[numerical_cols].fillna(medians)\n",
    "\n",
    "# upload each df to db\n",
    "symbols_df.to_sql(name='symbols', con=engine, if_exists='replace', index=False)\n",
    "quotes_df.to_sql(name='quotes', con=engine, if_exists='replace', index=False)\n",
    "financials_reported_df.to_sql(name='financials_reported', con=engine, if_exists='replace', index=False)\n",
    "basic_financials_with_median_df.to_sql(name='basic_financials', con=engine, if_exists='replace', index=False)\n",
    "news_df.to_sql(name='company_news', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "\n",
    "print(\"Data uploaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDS instance connection successful!\n",
      "Connected successfully to the database 'mayah_bosworth_sql_project'!\n"
     ]
    }
   ],
   "source": [
    "# load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# connection parameters\n",
    "username = os.getenv('username') \n",
    "password = os.getenv('password')  \n",
    "host = os.getenv('host') \n",
    "port = os.getenv('port')  \n",
    "database = os.getenv('database') \n",
    "\n",
    "# instance connection for testing\n",
    "test_engine = create_engine(f'mysql+pymysql://{username}:{password}@{host}:{port}')\n",
    "\n",
    "try:\n",
    "    with test_engine.connect() as test_connection:\n",
    "        print(\"RDS instance connection successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to RDS instance: {e}\")\n",
    "\n",
    "# if successful, connect to database\n",
    "engine = create_engine(f'mysql+pymysql://{username}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(f\"Connected successfully to the database '{database}'!\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to the database '{database}': {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
