{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment variables\n",
    "load_dotenv()\n",
    "\n",
    "username = os.getenv('username')\n",
    "password = os.getenv('password')\n",
    "host = os.getenv('host')\n",
    "port = os.getenv('port')\n",
    "database = os.getenv('database')\n",
    "\n",
    "engine = create_engine(f'mysql+pymysql://{username}:{password}@{host}:{port}/{database}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selenium driver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from website\n",
    "def extract_table_data(table_element):\n",
    "    rows = table_element.find_elements(By.TAG_NAME, 'tr')\n",
    "    headers = [header.text for header in rows[0].find_elements(By.TAG_NAME, 'th')]\n",
    "    data = [[td.text for td in row.find_elements(By.TAG_NAME, 'td')] for row in rows[1:]]\n",
    "    return pd.DataFrame(data, columns=headers)\n",
    "\n",
    "# change df to sql\n",
    "def dataframe_to_sql(df, table_name, engine):\n",
    "    df.to_sql(name=table_name, con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company symbols\n",
    "symbols = [\"JPM\", \"GS\", \"C\", \"JLL\", \"DIS\", \"TPR\", \"F\", \"XOM\", \"AAPL\", \"AMZN\", \"PFE\", \"MRK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty list for each symbol\n",
    "all_insider_transactions = []\n",
    "all_trading_volumes = []\n",
    "all_eps_trends = []\n",
    "all_eps_revisions = []\n",
    "all_growth_estimates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape data for each symbol\n",
    "for symbol in symbols:\n",
    "\n",
    "    # insider transactions\n",
    "    url = f'https://finance.yahoo.com/quote/{symbol}/insider-transactions'\n",
    "    driver.get(url)\n",
    "    time.sleep(10)\n",
    "    insider_table = driver.find_element(By.CLASS_NAME, 'svelte-1s2g2l0')\n",
    "    insider_transactions_df = extract_table_data(insider_table)\n",
    "    insider_transactions_df['Symbol'] = symbol\n",
    "    all_insider_transactions.append(insider_transactions_df)\n",
    "\n",
    "    # trading volume\n",
    "    url = f'https://finance.yahoo.com/quote/{symbol}/history?filter=history'\n",
    "    driver.get(url)\n",
    "    time.sleep(6)\n",
    "    trading_volume_table = driver.find_element(By.CSS_SELECTOR, '.table.svelte-ewueuo')\n",
    "    trading_volume_df = extract_table_data(trading_volume_table)\n",
    "    trading_volume_df['Symbol'] = symbol\n",
    "    all_trading_volumes.append(trading_volume_df)\n",
    "\n",
    "    # analyst ratings\n",
    "    url = f'https://finance.yahoo.com/quote/{symbol}/analysis'\n",
    "    driver.get(url)\n",
    "    time.sleep(10)\n",
    "    categories = {\n",
    "        'epsTrend': all_eps_trends,\n",
    "        'epsRevisions': all_eps_revisions,\n",
    "        'growthEstimate': all_growth_estimates\n",
    "    }\n",
    "    # extract data for each category\n",
    "    for category, container in categories.items():\n",
    "        section_element = driver.find_element(By.XPATH, f'//section[@data-testid=\"{category}\"]')\n",
    "        df = extract_table_data(section_element)\n",
    "        df['Symbol'] = symbol\n",
    "        container.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat dfs for each category and upload to SQL\n",
    "dataframe_to_sql(pd.concat(all_insider_transactions, ignore_index=True), 'insider_transactions', engine)\n",
    "dataframe_to_sql(pd.concat(all_trading_volumes, ignore_index=True), 'trading_volume', engine)\n",
    "dataframe_to_sql(pd.concat(all_eps_trends, ignore_index=True), 'eps_trend', engine)\n",
    "dataframe_to_sql(pd.concat(all_eps_revisions, ignore_index=True), 'eps_revisions', engine)\n",
    "dataframe_to_sql(pd.concat(all_growth_estimates, ignore_index=True), 'growth_estimate', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close selenium driver\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
